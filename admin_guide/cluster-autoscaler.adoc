[[configuring-cluster-auto-scaler-AWS]]
= Configuring the cluster auto-scaler in AWS
{product-author}
{product-version}
:data-uri:
:icons: font
:experimental:
:toc: macro
:toc-title:
:prewrap!:
:context: cluster-auto-scaler

toc::[]

You can configure an auto-scaler on your {product-title} cluster in Amazon Web
Services (AWS) to ensure that
enough nodes are active to run your pods and that the number of active nodes is
proportional to current demand.

[IMPORTANT]
====
The auto-scaler is a Technology Preview feature only.
ifdef::openshift-enterprise[]
Technology Preview features are not supported with Red Hat production service
level agreements (SLAs), might not be functionally complete, and Red Hat does
not recommend to use them for production. These features provide early access to
upcoming product features, enabling customers to test functionality and provide
feedback during the development process.

For more information on Red Hat Technology Preview features support scope, see
https://access.redhat.com/support/offerings/techpreview/.
endif::[]
====

[NOTE]
====
You can run the auto-scaler on only Amazon Web Services (AWS).
====

include::admin_guide/topics/about-cluster-auto-scaler.adoc[leveloffset=+1]

{product-title} Creating primed images::

[NOTE]
====
If you already have a pre-existing primed image you can skip this
section.
====

You can use the Ansible playbooks to automatically create and seal a
primed image that is suitable for use by a LC and its ASG. All the
attibutes in the following procedure must come from your existing AWS
cluster.

.Procedure

. Create an Ansible inventory file
+
----
[OSEv3:children]
masters
nodes
etcd

[OSEv3:vars]
openshift_deployment_type=openshift-enterprise
ansible_ssh_user=ec2-user
openshift_clusterid=mycluster
ansible_become=yes

[masters]
[etcd]
[nodes]
----

. Create Ansible build AMI provisioning variables file
+
[source,yaml]
----
openshift_deployment_type: openshift-enterprise <1>

openshift_aws_clusterid: mycluster <2>

openshift_aws_region: us-east-1 <3>

openshift_aws_create_vpc: false <4>

openshift_aws_vpc_name: production <5>

openshift_aws_subnet_az: us-east-1d <6>

openshift_aws_create_security_groups: false <7>

openshift_aws_ssh_key_name: production-ssh-key <8>
na
openshift_aws_base_ami: ami-12345678 <9>

openshift_aws_create_s3: False <10>

openshift_aws_build_ami_group: default <11>

rhsub_user: name@example.com <12>
rhsub_pass: password <13>
rhsub_pool: pool-id <14>

openshift_aws_vpc: <15>
  name: "{{ openshift_aws_vpc_name }}"
  cidr: 172.18.0.0/16
  subnets:
    us-east-1:
    - cidr: 172.18.0.0/20
      az: "us-east-1d"
----
<1> The type of installment
<2> The name of the existing OpenShift cluster
<3> The region the cluster is currently running in
<4> Disable the creation of a VPC
<5> The existing VPC name that the cluster is running in
<6> The name of the subnet the existing cluster is running in
<7> Disable the creation of security groups
<8> The key name to use for SSH access
<9> The base AMI (e.g., a RHEL 7 GA AMI)
<10> Disable the creation of an S3 bucket
<11> what/why was this again? TODO(frobware)
<12> Red Hat Subscription email address
<13> Red Hat Subscription password
<14> Red Hat Subscription Pool ID
<15> The existing VPC subnets that the cluster is running in

. Run the AWS-specific playbook to generate a primed image
+
----
# ansible-playbook -i inventory-file \
ifdef::openshift-enterprise[]
    /usr/openshift-ansible/playbooks/aws/openshift-cluster/build_ami.yml
endif::[]
ifdef::openshift-origin[]
    ~/openshift-ansible/playbooks/aws/openshift-cluster/build_ami.yml
endif::[]
    -e @build-ami-provisioning-vars.yaml
----

